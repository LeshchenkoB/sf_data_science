{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW_4\n",
    "### Задача: используя библиотеку kaggle-environments, реализующую функционал взаимодействия между виртуальными агентами в рамках нескольких популярных игр, реализовать самостоятельно несколько агентов и сравнить их в игре «камень-ножницы-бумага»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle_environments import make, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Опишем поведение агента, всегда играющего \"камень\" - это значение 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing rock_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rock_agent.py\n",
    "\n",
    "#Example of the simple agent\n",
    "#0 - rock\n",
    "#1 - paper\n",
    "#2 - scissors\n",
    "def your_agent(observation, configuration):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Опишем агента, который производит то же самое действие, что и оппонент на прошлом ходу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting copy_opponent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile copy_opponent.py\n",
    "import random\n",
    "\n",
    "#Example \n",
    "def copy_opponent(observation, configuration):\n",
    "    #in case we have information about opponent last move\n",
    "    if observation.step > 0:\n",
    "        return observation.lastOpponentAction\n",
    "    #initial step\n",
    "    else:\n",
    "        return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Агент, играющий всегда \"ножницы\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scissors_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scissors_agent.py\n",
    "def scissors_agent(observation, configuration):\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Агент, всегда играющий \"бумагу\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing paper_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile paper_agent.py\n",
    "def paper_agent(observation, configuration):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Агент с последовательностью случайных ходов, но с предпочтением одного варианта (60%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing biased_random_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile biased_random_agent.py\n",
    "import random\n",
    "\n",
    "def biased_random_agent(observation, configuration):\n",
    "    # С вероятностью 60% выбирает \"камень\", иначе случайный ход\n",
    "    return 0 if random.random() < 0.6 else random.randrange(1, configuration.signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Агент, играющий против предыдущего хода оппонента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting counter_opponent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile counter_opponent.py\n",
    "import random\n",
    "\n",
    "def counter_opponent(observation, configuration):\n",
    "    if observation.step == 0:\n",
    "        # На первом ходе агент выбирает случайный ход, так как у него нет информации о предыдущем ходе оппонента.\n",
    "        return random.randrange(0, configuration.signs)  # Можно использовать любой ход в диапазоне от 0 до 2.\n",
    "    else:\n",
    "        # Получаем предыдущий ход оппонента.\n",
    "        opponent_previous_move = observation.lastOpponentAction\n",
    "        \n",
    "        # Выбираем ход, который побеждает предыдущий ход оппонента.\n",
    "        # (opponent_previous_move + 1) % 3 выбирает следующий ход в цикле 0 -> 1 -> 2 -> 0.\n",
    "        return (opponent_previous_move + 1) % configuration.signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Агент со случайной стратегией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing random_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile random_agent.py\n",
    "import random\n",
    "\n",
    "def random_agent(observation, configuration):\n",
    "    return random.randrange(0, configuration.signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Агент с повторением своих же кодов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting repeat_self_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile repeat_self_agent.py\n",
    "import random\n",
    "# Инициализируем переменную last_action, которая будет хранить последний выполненный ход агента.\n",
    "last_action = 0\n",
    "\n",
    "def repeat_self_agent(observation, configuration):\n",
    "    global last_action\n",
    "    if observation.step == 0:\n",
    "        # Если это первый шаг, выбираем случайное действие из возможных ходов (от 0 до configuration.signs - 1)\n",
    "        last_action = random.randrange(0, configuration.signs)\n",
    "    return last_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Агент, выбирающий случайный ход каждые три раунда:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting random_every_three_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile random_every_three_agent.py\n",
    "import random\n",
    "\n",
    "def random_every_three_agent(observation, configuration):\n",
    "    if observation.step % 3 == 0:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "    else:\n",
    "        return observation.lastOpponentAction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Агент с предсказанием на основе тенденции оппонента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trend_predictor_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trend_predictor_agent.py\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "last_actions = deque(maxlen=5)\n",
    "\n",
    "def trend_predictor_agent(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        last_actions.append(observation.lastOpponentAction)\n",
    "    if len(last_actions) >= 3 and len(set(last_actions)) == 1:\n",
    "        return (last_actions[-1] + 1) % configuration.signs\n",
    "    return random.randrange(0, configuration.signs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Агент с ротацией ходов по фиксированному шаблону (камень, бумага, ножницы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing rotate_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rotate_agent.py\n",
    "\n",
    "rotation = [0, 1, 2]\n",
    "\n",
    "def rotate_agent(observation, configuration):\n",
    "    return rotation[observation.step % 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Агент, следящий за ходами с конца и реагирующий на них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting last_move_reactor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile last_move_reactor.py\n",
    "\n",
    "def last_move_reactor(observation, configuration):\n",
    "    if observation.step > 0:\n",
    "        return (observation.lastOpponentAction + 2) % configuration.signs\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Агент, копирующий свой предыдущий ход:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mimic_self_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mimic_self_agent.py\n",
    "import random\n",
    "\n",
    "last_move = 0\n",
    "\n",
    "def mimic_self_agent(observation, configuration):\n",
    "    global last_move\n",
    "    if observation.step > 0:\n",
    "        return last_move\n",
    "    else:\n",
    "        last_move = random.randrange(0, configuration.signs)\n",
    "        return last_move\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Агент, чередующийся между случайным и предсказуемым ходом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting alternate_strategy_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile alternate_strategy_agent.py\n",
    "import random\n",
    "\n",
    "def alternate_strategy_agent(observation, configuration):\n",
    "    if observation.step % 2 == 0:\n",
    "        return random.randrange(0, configuration.signs)\n",
    "    else:\n",
    "        return (observation.step + 1) % configuration.signs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Агент, который меняет стратегию каждые пять ходов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting change_strategy_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile change_strategy_agent.py\n",
    "import random\n",
    "\n",
    "strategies = [0, 1, 2]\n",
    "\n",
    "def change_strategy_agent(observation, configuration):\n",
    "    if observation.step % 5 == 0:\n",
    "        return strategies[observation.step // 5 % len(strategies)]\n",
    "    return random.randrange(0, configuration.signs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Турнирное тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат между rock_agent.py и scissors_agent.py: [[99.0, -99.0]]\n",
      "Результат между rock_agent.py и paper_agent.py: [[-99.0, 99.0]]\n",
      "Результат между rock_agent.py и biased_random_agent.py: [[0, 0]]\n",
      "Результат между rock_agent.py и counter_opponent.py: [[-98.0, 98.0]]\n",
      "Результат между rock_agent.py и repeat_self_agent.py: [[99.0, -99.0]]\n",
      "Результат между rock_agent.py и random_every_three_agent.py: [[0, 0]]\n",
      "Результат между rock_agent.py и trend_predictor_agent.py: [[-98.0, 98.0]]\n",
      "Результат между rock_agent.py и rotate_agent.py: [[0, 0]]\n",
      "Результат между rock_agent.py и last_move_reactor.py: [[98.0, -98.0]]\n",
      "Результат между rock_agent.py и mimic_self_agent.py: [[99.0, -99.0]]\n",
      "Результат между rock_agent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между rock_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между scissors_agent.py и paper_agent.py: [[99.0, -99.0]]\n",
      "Результат между scissors_agent.py и biased_random_agent.py: [[-50.0, 50.0]]\n",
      "Результат между scissors_agent.py и counter_opponent.py: [[-97.0, 97.0]]\n",
      "Результат между scissors_agent.py и repeat_self_agent.py: [[0, 0]]\n",
      "Результат между scissors_agent.py и random_every_three_agent.py: [[0, 0]]\n",
      "Результат между scissors_agent.py и trend_predictor_agent.py: [[-95.0, 95.0]]\n",
      "Результат между scissors_agent.py и rotate_agent.py: [[0, 0]]\n",
      "Результат между scissors_agent.py и last_move_reactor.py: [[97.0, -97.0]]\n",
      "Результат между scissors_agent.py и mimic_self_agent.py: [[0, 0]]\n",
      "Результат между scissors_agent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между scissors_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между paper_agent.py и biased_random_agent.py: [[39.0, -39.0]]\n",
      "Результат между paper_agent.py и counter_opponent.py: [[-98.0, 98.0]]\n",
      "Результат между paper_agent.py и repeat_self_agent.py: [[99.0, -99.0]]\n",
      "Результат между paper_agent.py и random_every_three_agent.py: [[0, 0]]\n",
      "Результат между paper_agent.py и trend_predictor_agent.py: [[-94.0, 94.0]]\n",
      "Результат между paper_agent.py и rotate_agent.py: [[0, 0]]\n",
      "Результат между paper_agent.py и last_move_reactor.py: [[99.0, -99.0]]\n",
      "Результат между paper_agent.py и mimic_self_agent.py: [[0, 0]]\n",
      "Результат между paper_agent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между paper_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между biased_random_agent.py и counter_opponent.py: [[0, 0]]\n",
      "Результат между biased_random_agent.py и repeat_self_agent.py: [[37.0, -37.0]]\n",
      "Результат между biased_random_agent.py и random_every_three_agent.py: [[0, 0]]\n",
      "Результат между biased_random_agent.py и trend_predictor_agent.py: [[0, 0]]\n",
      "Результат между biased_random_agent.py и rotate_agent.py: [[0, 0]]\n",
      "Результат между biased_random_agent.py и last_move_reactor.py: [[0, 0]]\n",
      "Результат между biased_random_agent.py и mimic_self_agent.py: [[45.0, -45.0]]\n",
      "Результат между biased_random_agent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между biased_random_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между counter_opponent.py и repeat_self_agent.py: [[99.0, -99.0]]\n",
      "Результат между counter_opponent.py и random_every_three_agent.py: [[0, 0]]\n",
      "Результат между counter_opponent.py и trend_predictor_agent.py: [[0, 0]]\n",
      "Результат между counter_opponent.py и rotate_agent.py: [[0, 0]]\n",
      "Результат между counter_opponent.py и last_move_reactor.py: [[-50.0, 50.0]]\n",
      "Результат между counter_opponent.py и mimic_self_agent.py: [[97.0, -97.0]]\n",
      "Результат между counter_opponent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между counter_opponent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между repeat_self_agent.py и random_every_three_agent.py: [[0, 0]]\n",
      "Результат между repeat_self_agent.py и trend_predictor_agent.py: [[-94.0, 94.0]]\n",
      "Результат между repeat_self_agent.py и rotate_agent.py: [[0, 0]]\n",
      "Результат между repeat_self_agent.py и last_move_reactor.py: [[99.0, -99.0]]\n",
      "Результат между repeat_self_agent.py и mimic_self_agent.py: [[0, 0]]\n",
      "Результат между repeat_self_agent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между repeat_self_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между random_every_three_agent.py и trend_predictor_agent.py: [[0, 0]]\n",
      "Результат между random_every_three_agent.py и rotate_agent.py: [[-73.0, 73.0]]\n",
      "Результат между random_every_three_agent.py и last_move_reactor.py: [[0, 0]]\n",
      "Результат между random_every_three_agent.py и mimic_self_agent.py: [[0, 0]]\n",
      "Результат между random_every_three_agent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между random_every_three_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между trend_predictor_agent.py и rotate_agent.py: [[0, 0]]\n",
      "Результат между trend_predictor_agent.py и last_move_reactor.py: [[69.0, -69.0]]\n",
      "Результат между trend_predictor_agent.py и mimic_self_agent.py: [[97.0, -97.0]]\n",
      "Результат между trend_predictor_agent.py и alternate_strategy_agent.py: [[-23.0, 23.0]]\n",
      "Результат между trend_predictor_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между rotate_agent.py и last_move_reactor.py: [[-98.0, 98.0]]\n",
      "Результат между rotate_agent.py и mimic_self_agent.py: [[0, 0]]\n",
      "Результат между rotate_agent.py и alternate_strategy_agent.py: [[-45.0, 45.0]]\n",
      "Результат между rotate_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между last_move_reactor.py и mimic_self_agent.py: [[-98.0, 98.0]]\n",
      "Результат между last_move_reactor.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между last_move_reactor.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между mimic_self_agent.py и alternate_strategy_agent.py: [[0, 0]]\n",
      "Результат между mimic_self_agent.py и change_strategy_agent.py: [[0, 0]]\n",
      "Результат между alternate_strategy_agent.py и change_strategy_agent.py: [[0, 0]]\n"
     ]
    }
   ],
   "source": [
    "agents = [\n",
    "    \"rock_agent.py\", \"scissors_agent.py\", \"paper_agent.py\",\n",
    "    \"biased_random_agent.py\", \"counter_opponent.py\", \"repeat_self_agent.py\",\n",
    "    \"random_every_three_agent.py\", \"trend_predictor_agent.py\", \"rotate_agent.py\",\n",
    "    \"last_move_reactor.py\", \"mimic_self_agent.py\", \"alternate_strategy_agent.py\",\n",
    "    \"change_strategy_agent.py\"\n",
    "]\n",
    "\n",
    "# Запуск турнира между всеми агентами\n",
    "for i in range(len(agents)):\n",
    "    for j in range(i + 1, len(agents)):\n",
    "        result = evaluate(\n",
    "            \"rps\",\n",
    "            [agents[i], agents[j]],\n",
    "            configuration={\"episodeSteps\": 100}\n",
    "        )\n",
    "        print(f\"Результат между {agents[i]} и {agents[j]}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"rps\", #environment to use - no need to change\n",
    "    [\"rock_agent.py\", \"copy_opponent.py\"], #agents to evaluate\n",
    "    configuration={\"episodeSteps\": 100} #number of episodes \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-99.0, 99.0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    \"rps\", #environment to use - no need to change\n",
    "    [\"rock_agent.py\", \"paper\"], #agents to evaluate\n",
    "    configuration={\"episodeSteps\": 100} #number of episodes \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
